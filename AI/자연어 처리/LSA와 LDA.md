# 잠재 의미 분석(Latent Semantic Analysis, LSA)

**잠재 의미 분석(Latent Semantic Analysis, LSA)**은 자연어 처리 분야에서 문서와 단어 간의 숨겨진 의미 관계를 발견하기 위한 통계적 기법이다. 이는 주어진 문서 집합에서 단어들의 공동 발생 패턴을 분석하여, 단어와 문서 간의 잠재된 의미 구조를 파악하는 데 사용된다.

## LSA의 기본 개념

LSA는 다음과 같은 절차를 따른다:

1. **문서-단어 행렬(DTM) 생성**: 문서 집합에서 각 문서와 단어의 발생 빈도를 나타내는 행렬을 만든다.

2. **특이값 분해(Singular Value Decomposition, SVD)**: DTM에 SVD를 적용하여 세 개의 행렬로 분해한다. 이를 통해 데이터의 차원을 축소하고 노이즈를 제거하여 숨겨진 의미를 추출한다.

3. **차원 축소**: 특이값 중 상위 t개만 남기고 나머지를 제거하여 데이터의 차원을 축소한다. 이를 통해 중요한 의미를 가진 정보만을 남기고, 불필요한 정보를 제거한다.

## LSA의 수행 과정

LSA의 수행 과정은 다음과 같다:

1. **문서-단어 행렬(DTM) 생성**: 문서 집합에서 각 문서와 단어의 발생 빈도를 나타내는 행렬을 만든다.

2. **특이값 분해(SVD) 수행**: DTM에 SVD를 적용하여 U, Σ, V^T 행렬로 분해한다.

3. **차원 축소**: Σ 행렬의 상위 t개의 특이값만 남기고 나머지를 제거하여 차원을 축소한다.

4. **잠재 의미 공간 구성**: 축소된 U, Σ, V^T 행렬을 이용하여 단어와 문서를 잠재 의미 공간에 매핑한다.

5. **유사도 계산**: 잠재 의미 공간에서 단어와 문서 간의 유사도를 계산하여 의미적 관계를 파악한다.

# 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)

토픽 모델링은 문서 집합에서 주제를 추출하는 과정으로, 검색 엔진이나 고객 민원 시스템 등에서 문서의 주제를 파악하는 데 유용하게 사용된다. 그 중에서도 **잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)**은 대표적인 토픽 모델링 알고리즘이다.

## LDA의 기본 개념

LDA는 다음과 같은 가정을 기반으로 한다:

- **문서들은 여러 토픽의 혼합으로 구성되어 있다.**
- **각 토픽은 특정 단어들이 나타날 확률 분포를 가진다.**

이러한 가정 하에, LDA는 주어진 문서 집합에서 다음을 추정한다:

- **각 문서가 어떤 토픽들로 이루어져 있는지에 대한 분포**
- **각 토픽이 어떤 단어들로 이루어져 있는지에 대한 분포**

## LDA의 수행 과정

LDA의 수행 과정은 다음과 같다:

1. **토픽의 개수(k)를 설정한다.**
   - 사용자가 알고리즘에 몇 개의 토픽을 찾을지 지정해야 한다.
   - 이 값은 경험이나 사전 지식을 통해 결정된다.

2. **모든 단어를 무작위로 k개의 토픽 중 하나에 할당한다.**
   - 초기에는 각 단어를 임의의 토픽에 할당하여 시작한다.

3. **반복(iterative) 과정:**
   - 각 단어에 대해 다음을 수행한다:
     - **현재 단어를 제외한 다른 단어들의 토픽 할당이 모두 올바르다고 가정한다.**
     - **두 가지 기준에 따라 현재 단어의 토픽을 재할당한다:**
       - 해당 문서에서 특정 토픽이 할당된 단어들의 비율
       - 특정 토픽에서 해당 단어가 나타날 확률

이러한 과정을 여러 번 반복하여 토픽 할당이 수렴되면, 최종적으로 각 문서의 토픽 분포와 각 토픽의 단어 분포를 얻을 수 있다.

## LDA와 잠재 의미 분석(LSA)의 차이

- **LSA**: DTM(Document-Term Matrix)을 차원 축소하여 근접한 단어들을 토픽으로 묶는다.
- **LDA**: 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 추정하여 토픽을 추출한다.

---

## 참고

- <https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation>
- <https://ko.wikipedia.org/wiki/%EC%9E%A0%EC%9E%AC_%EC%9D%98%EB%AF%B8_%EB%B6%84%EC%84%9D>
- <https://wikidocs.net/24949>
- <https://wikidocs.net/184237>
