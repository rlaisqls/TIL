> <https://transformer-circuits.pub/2025/attribution-graphs/methods.html#global-weights>
> 위 글의 이해를 위한 번역, 정리글입니다.

# Circuit Tracing: Revealing Computational Graphs in Language Models

- 딥러닝 모델은 수많은 계산 단위(인공 뉴런)의 작용으로 출력을 생성한다.
- 딥러닝 모델을 인간이 이해 가능한 언어로 설명하는 것은 바이너리 프로그램을 리버스 엔지니어링하는 것과 유사한 역추적이 필요하며, 이 분야에 대한 연구를 Mechanistic interpretability(MI)라고 부른다.

- Anthropic 팀은 이를 이해하기 위해
  1. 우선 모델이 계산에 사용하는 특징(feature)을 식별하고,
  2. 이러한 특징들이 상호 작용하여 모델 출력을 생성하는 과정을 설명하려 했다.

- 기본적으로 활성화 함수와 가중치로 계산하는 작은 단위의 원시 뉴런으로 모델을 설명할 수 있다.
  - 이전 연구에서 이 방법으로 비전 모델에서 흥미로운 회로를 찾아내기도 했다. (<https://distill.pub/2020/circuits>)
  - 그러나 모델 뉴런은 종종 다의미적(polysemantic), 즉 여러 관련 없는 개념의 혼합을 나타낸다.
  - 이는 모델이 뉴런 수보다 더 많은 개념을 표현해야 해서, 개념 표현이 여러 뉴런에 번져있기 때문이다.
  - 하여 계산 단위와 의미 단위의 불일치는 여전히 연구 발전의 장애물로 남아있었다.

- 최근 몇 년간, sparse autoencoders(SAEs), transcoder, crosscoders 같은 [sparse coding model](https://en.wikipedia.org/wiki/Sparse_dictionary_learning)이 중첩(superposition)된 방식으로 표현된 해석 가능한 특징(interpretable features)을 식별하는 데 유망한 도구로 주목받고 있다
  - (희소 코딩(sparse coding)은 모델이 모든 뉴런을 동시에 사용하는 게 아니라, 소수의 뉴런만 활성화시켜서 정보를 표현하게 만드는 기법이다.)
  - 현재의 희소 부호화 방법들은 특징을 식별하는 데 완벽하진 않지만(7절 한계 참고), 충분히 해석 가능한 결과를 제공할 수 있다 판단하고 연구를 진행했다.

- 따라서, 이어지는 글에서 Anthropic 팀이 현재 사용하고 있는 접근 방식과 이에 포함된 여러 핵심 방법론적 결정을 설명하고자 한다:

  1. 트랜스코더(Transcoders)
  - SAEs(희소 오토인코더) 대신 트랜스코더의 변형을 사용해 특징을 추출한다.
  - 이를 통해 원래 모델의 대체 역할을 할 수 있는, 해석 가능한 "대체 모델(replacement model)"을 구성할 수 있다.
  - 이 방식은 특히 특징 간 직접 상호작용을 분석할 수 있다는 점에서 중요하다.

  2. 크로스-레이어(Cross-Layer)
  - CLT(Cross Layer Transcoder)를 기반으로 분석을 수행한다.
  - 여기서 각각의 feature는 한 레이어의 residual stream을 읽고, 이후 모든 MLP 레이어에 기여한다.
  - 이 구조는 회로를 단순화시켜준다. 놀랍게도, Anthropic 팀은 학습된 CLT 특징들을 모델의 MLP 대신 사용하면서도, 약 50%의 경우에서 원래 모델과 같은 출력을 얻을 수 있다고 한다.

  3. 속성 그래프(Attribution Graphs)
  - 각 토큰 출력에 어떤 특징이 얼마나 기여했는지를 그래프 형태로 시각화한 **속성 그래프(attribution graphs)**를 분석 대상으로 삼는다.
    - (이는 모델의 “생각 흐름”을 따라가는 것과 유사하다) [참고](https://arxiv.org/pdf/2406.11944)
  - 그래프의 노드는 활성화된 특징들, 프롬프트의 토큰 임베딩, 재구성 오류, 출력 로짓 등을 나타내고, 엣지는 노드 간의 **선형적 효과(linear effect)**를 표현한다.

  4. 특징 간 선형적 귀속(Linear Attribution Between Features)
  - 입력에 대해 특징 간의 직접 상호작용이 선형이 되도록 한다.
  - 일반적으로 MLP는 ReLU 같은 비선형 함수 때문에 해석이 어려운 연산을 한다.
    - 이를 위해 선형으로 만들기 위해 트랜스코더 특징들이 MLP의 비선형 연산을 ‘건너뛰며’(bridge over) 이를 대체하는 방식으로 작동시키고,
    - 이 외에 남아있는 비선형성—어텐션 패턴과 정규화 분모—를 고정(freeze)한다.
  - 엄밀히 말하면, 특징의 **사전 활성화 값(pre-activation)**이 이전 특징들의 활성화에 대해 선형이다.
  - attention을 freezing하는 패턴은 일반적인 접근 방식으로, 트랜스포머를 이해하는 문제를 두 단계로 나누는 것이다:
     1. 고정된 어텐션 패턴이 주어졌을 때 모델이 어떻게 동작하는지 이해하기
     2. 모델이 왜 특정 위치에 어텐션을 주는지 이해하기.
  - 어텐션 패턴을 따로 떼어놓고 이해하는 방식은 몇 가지 문재를 초래할 수 있으나, (결손된 어텐션 회로 문제)
  - [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html)에서 제시했듯 QK 회로(Query-Key Circuits)를 분석하는 방식을 해결책으로 따라갈 수 있다.

  5. 가지치기(Pruning)
  - 특징들이 희소해졌더라도, 하나의 프롬프트에 대해 너무 많은 특징이 활성화된다면 그래프 해석이 어렵다.
  - 따라서 특정 토큰 출력에 가장 크게 기여하는 노드와 엣지를 식별하여 그래프를 제외한 나머지를 가지치기한다.
  - 이렇게 하면 간결하고 해석 가능한 계산 그래프를 얻을 수 있다. (참고)

  6. 인터페이스(Interface)
  - 팀에서 속성 그래프를 시각적으로 탐색하고, 그 안의 특징들을 분석할 수 있는 인터랙티브 인터페이스를 개발하여 사용했다.
  - 연구자는 이 도구를 통해 핵심 메커니즘을 빠르게 식별하고 하이라이트할 수 있다. (자랑을 이렇게..)

  7. 검증(Validation)
  - 이러한 회로 분석 방식은 간접적이기 때문에, 대체 모델이 원래 모델과 다른 메커니즘을 사용할 수도 있다.
  - 따라서 그래프에서 찾은 메커니즘이 타당한지를 검증하기 위해 **교란 실험(perturbation experiments)**을 수행한다.
  - 즉, 특정 특징의 방향으로 교란을 가했을 때, 다른 특징의 활성화나 모델 출력이 속성 그래프와 일치하는지를 측정한다.

  8. 글로벌 가중치(Global Weights)
  - 본 논문은 개별 프롬프트에 대한 속성 그래프 분석에 주로 초점을 맞추지만, 이 방법론을 사용하여 **대체 모델의 가중치 자체(글로벌 가중치)**를 직접 분석하는 것도 가능하다.
  - 글로벌 가중치는 다양한 프롬프트에 공통적으로 작동하는 메커니즘을 나타낸다.
  - 그러나 아래에서 설명하듯, 글로벌 가중치는 그래프보다 해석이 어렵고, 가중치 간 간섭 문제가 발생할 수 있다. 그럼에도 불구하고, 이를 사용해 작은 수 덧셈 회로를 성공적으로 분석할 수 있었다.

이 논문의 목표는 몇 가지 사례 연구를 통해 우리의 방법론을 상세히 설명하고 검증하는 것이다. 본 내용을 아래의 목차로 이어서 설명한다.

1. **대체 모델(replacement model)**, *속성 그래프(attribution graph)** 구성
    - 두 가지 사례 연구—§ 3.7 사실 회상(Factual Recall), § 3.8 덧셈(Addition)—로 이를 설명

2. **글로벌 회로(global circuits)** 구성

3. **크로스-레이어 트랜스코더(CLT)**와 그 결과로 생성된 속성 그래프의 정량적 평가

    - CLT가 기존 뉴런이나 레이어별 트랜스코더에 비해 **파레토 개선(Pareto-improvements)**을 보인다는 지표를 통해 그 효과를 입증

4. **동반 논문(companion paper)** 소개
   - 이 방법을 Claude 3.5 Haiku 모델에 적용하여, 복수 단계 추론, 계획(planning), 환각(hallucination) 등의 다양한 행동을 분석함

5. 한계점 논의.
   - 여기에는 어텐션 패턴의 역할, 재구성 오류의 영향, 억제 회로(suppression motifs)의 식별,
   - 글로벌 회로를 이해하는 데 따르는 어려움 등이 포함됨.
   - 이러한 한계를 극복하고 나면, 모델의 추가적인 작동 메커니즘들이 드러날 가능성이 있으며, 이는 향후 연구에서 매우 유망한 방향이다.

6. 속성 그래프를 생성하는 방법의 설계 공간에 대한 폭넓은 논의 (§ 8 논의)를 하고,
   - 우리 접근법의 구성 요소들이 다른 기법들과 어떻게 조합될 수 있는지를 설명한다.
   - 그리고 관련 연구에 대한 개요로 논문을 마무리한다 (§ 9 관련 연구).

---

## Building an Interpretable Replacement Model

#### Cross-Layer Transcoder

하나의 Feature는 한 레이어에서 읽고, 모든 레이어에 쓴다.

<img width="500" alt="image" src="https://github.com/user-attachments/assets/ce5b794d-9877-40ea-a2ed-859187d28315" />

- cross-layer transcoder(CLT)는 뉴런("features")로 구성되어있고, 기본 모델과 동일한 L개의 레이어로 구성된다.
- 이 모델의 목표는 기존 모델의 MLP 출력을 sparsely active feature로 재구성하는 것이다.
- 특징(feature)**들은 자신이 속한 레이어에서 모델의 residual stream으로부터 입력을 받지만, cross layer라는 이름처럼, 그 출력은 이후 모든 레이어에 걸쳐 전달될 수 있다.
- CLT 외에도 다양한 아키텍처들이 회로 분석에 사용될 수 있지만, 아래 이유로  CLT가 잘 작동한다는 것을 확인했다.
  - ℓ번째 레이어의 각 특징은 그 레이어의 residual stream으로부터 입력을 받아, 선형 인코더(linear encoder)를 거친 후 비선형 함수(nonlinearity)를 적용해 활성화된다.
  - ℓ번째 레이어의 특징은 ℓ, ℓ+1, ..., L번째 레이어의 MLP 출력을 복원하는 데 기여하며, 각 출력 레이어에 대해 별도의 선형 디코더 가중치를 사용한다.
  - 모든 레이어의 모든 특징들은 함께(jointly) 학습된다. 그 결과, ℓ′번째 레이어의 MLP 출력은 그 이전의 모든 레이어들의 특징들에 의해 함께 복원된다.

**다양한 크기의 CLT(크로스-레이어 트랜스코더)**를 **소형 18-레이어 트랜스포머 모델(“18L”)**과 Claude 3.5 Haiku 모델에 대해 학습시켰다.
 18L 모델은 0번째 레이어에 MLP가 없기 때문에, 우리의 CLT는 총 17개의 레이어로 구성된다.

- [상세한 구현에 대한 설명](<https://transformer-circuits.pub/2025/attribution-graphs/methods.html#appendix-ml-details-ml>)

---
참고

- <https://distill.pub/2020/circuits/curve-circuit>
